{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0966f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.retrievers import (\n",
    "    ContextualCompressionRetriever,\n",
    "    # DocumentCompressorPipeline,\n",
    "    MergerRetriever,\n",
    ")\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_community.document_transformers import (\n",
    "    EmbeddingsClusteringFilter,\n",
    "    EmbeddingsRedundantFilter,\n",
    ")\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "from langchain.retrievers.document_compressors import EmbeddingsFilter, DocumentCompressorPipeline\n",
    "from langchain_community.document_transformers import EmbeddingsRedundantFilter, LongContextReorder\n",
    "from langchain import hub\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38c65a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Li_gpt_base:\n",
    "    def __init__(self):\n",
    "        self.load_env_variables(\".env\")\n",
    "        self.openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "        self.db_dir = 'db'\n",
    "        self.model_kwargs = {'device': 'cuda:0'}\n",
    "        self.encode_kwargs = {'normalize_embeddings': True}\n",
    "        \n",
    "        self.setup_embeddings()\n",
    "        self.configure_databases()\n",
    "        self.initialize_retrievers()\n",
    "        self.configure_pipeline()\n",
    "        self.setup_llm()\n",
    "\n",
    "    def load_env_variables(self, filename):\n",
    "        with open(filename) as f:\n",
    "            for line in f:\n",
    "                key, value = line.strip().split('=')\n",
    "                os.environ[key] = value\n",
    "\n",
    "    def setup_embeddings(self):\n",
    "        self.material_embedding = HuggingFaceEmbeddings(model_name=\"pranav-s/MaterialsBERT\", model_kwargs=self.model_kwargs, encode_kwargs=self.encode_kwargs)\n",
    "        self.bio_embedding = HuggingFaceEmbeddings(model_name=\"dmis-lab/biobert-v1.1\", model_kwargs=self.model_kwargs, encode_kwargs=self.encode_kwargs)\n",
    "        self.filter_embeddings = OpenAIEmbeddings()\n",
    "\n",
    "    def configure_databases(self):\n",
    "        client_settings = chromadb.config.Settings(\n",
    "            is_persistent=True,\n",
    "            persist_directory=self.db_dir,\n",
    "            anonymized_telemetry=False\n",
    "        )\n",
    "        self.db_material = Chroma(\n",
    "            collection_name=\"project_store_material\",\n",
    "            persist_directory=self.db_dir,\n",
    "            client_settings=client_settings,\n",
    "            embedding_function=self.material_embedding,\n",
    "        )\n",
    "\n",
    "        self.db_bio = Chroma(\n",
    "            collection_name=\"project_store_bio\",\n",
    "            persist_directory=self.db_dir,\n",
    "            client_settings=client_settings,\n",
    "            embedding_function=self.bio_embedding,\n",
    "        )\n",
    "\n",
    "    def initialize_retrievers(self):\n",
    "        retriever_all = self.db_material.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10})\n",
    "        retriever_multi_qa = self.db_bio.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 10})\n",
    "        self.lotr = MergerRetriever(retrievers=[retriever_all, retriever_multi_qa])\n",
    "\n",
    "    def configure_pipeline(self):\n",
    "        redundent_filter = EmbeddingsRedundantFilter(embeddings=self.filter_embeddings)\n",
    "        reordering = LongContextReorder()\n",
    "        pipeline = DocumentCompressorPipeline(transformers=[redundent_filter, reordering])\n",
    "        self.compression_retriever = ContextualCompressionRetriever(base_compressor=pipeline, base_retriever=self.lotr)\n",
    "\n",
    "    def setup_llm(self):\n",
    "        self.llm = ChatOpenAI(model_name=\"gpt-4-turbo\", temperature=0, api_key=self.openai_api_key)\n",
    "\n",
    "    def run(self, context, question):\n",
    "        prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "        \n",
    "        rag_chain = ({\"context\": self.compression_retriever | self.format_docs, \"question\": RunnablePassthrough()} | prompt | self.llm | StrOutputParser())\n",
    "        return rag_chain\n",
    "\n",
    "    @staticmethod\n",
    "    def format_docs(docs):\n",
    "        return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    def generate_questions(self, questions):\n",
    "        for chunk in self.run(\"filler context\", \"filler question\").stream(questions):\n",
    "            print(chunk, end=\"\", flush=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52c76c5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No sentence-transformers model found with name pranav-s/MaterialsBERT. Creating a new one with MEAN pooling.\n",
      "Some weights of BertModel were not initialized from the model checkpoint at pranav-s/MaterialsBERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "No sentence-transformers model found with name dmis-lab/biobert-v1.1. Creating a new one with MEAN pooling.\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "Li_gpt = Li_gpt_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2ea6155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The electrolyte composed of fluorinated 1,4-dimethoxylbutane paired with 1 M lithium bis(fluorosulfonyl)imide demonstrates a Coulombic efficiency of approximately 99.52%. This electrolyte also shows excellent compatibility with both lithium metal anodes and high-voltage cathodes. It retains 90% capacity after 420 cycles with an average Coulombic efficiency of 99.98%."
     ]
    }
   ],
   "source": [
    "Li_gpt.generate_questions(\"Can you provide some electrolyte and with corresponding Coulombic efficiency of 99.5?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.11 64-bit (microsoft store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "40ea231ce006ed65b013ba3e9b5a48267321b4d32b910ea3a649228a606377c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
